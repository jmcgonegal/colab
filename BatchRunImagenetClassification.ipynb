{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BatchRunImagenetClassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmcgonegal/colab/blob/master/BatchRunImagenetClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "AOWLPTtBRxKN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense, Convolution2D, MaxPooling2D, Activation, BatchNormalization, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "\n",
        "filepath=\"weights.best.hdf5\"\n",
        "fill_mode='nearest'\n",
        "\n",
        "train_data_dir = 'train' # we are just doing this to be lazy about getting a list of classes\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    fill_mode=fill_mode)\n",
        "\n",
        "# path to the model weights files.\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 384, 384\n",
        "\n",
        "batch_size = 1 # how many images to train in the batch (limited by size of memory)\n",
        "class_mode='categorical'\n",
        "    \n",
        "# images we will use for validation\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode=class_mode)\n",
        "\n",
        "# our image shape width,height,rgb\n",
        "input_shape = (img_width, img_height, 3)\n",
        "\n",
        "# build the VGG16/VGG19 network\n",
        "vgg_model = applications.VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# dont adjust weights of these layers\n",
        "for i in range(len(vgg_model.layers)):\n",
        "    vgg_model.layers[i].trainable = False\n",
        "    \n",
        "# build our training model\n",
        "top_model = Sequential()\n",
        "top_model.add(vgg_model)\n",
        "top_model.add(Flatten(input_shape=input_shape))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "top_model.summary()\n",
        "\n",
        "# todo check to make sure file exists\n",
        "top_model.load_weights(filepath)\n",
        "\n",
        "# compile the model\n",
        "top_model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizers.Adam(lr=1e-5), \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "print('Model loaded')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnSoj3G0RsQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "labels = (validation_generator.class_indices) \n",
        "labels = dict((v,k) for k,v in labels.items()) # reverse key and value for label lookup\n",
        "\n",
        "unclass_gen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    fill_mode=fill_mode)\n",
        "\n",
        "unclassified_generator = unclass_gen.flow_from_directory(\n",
        "    'unsorted',\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=1,\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,\n",
        "    shuffle=False)\n",
        "\n",
        "# make the directory we will copy our sorted images to\n",
        "destPath = os.path.join('classified')\n",
        "if not os.path.exists(destPath):\n",
        "    os.mkdir(destPath)\n",
        "\n",
        "count=0 # we are not shuffled\n",
        "for gen in unclassified_generator:\n",
        "    # loop until we have viewed every file\n",
        "    if count >= len(unclassified_generator.filenames):\n",
        "        break\n",
        "    for ix, img in enumerate(gen):\n",
        "        \n",
        "        filename = unclassified_generator.filenames[count]\n",
        "        count+=1\n",
        "        \n",
        "        ximg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2] ))\n",
        "\n",
        "        \n",
        "        classes = top_model.predict_classes(ximg)\n",
        "\n",
        "        label = labels[classes[ix]]\n",
        "\n",
        "        src = os.path.realpath(os.path.join('unsorted',filename))\n",
        "        dest = os.path.realpath(os.path.join('classified',label))\n",
        "        print(src,'->',dest+'/')\n",
        "        \n",
        "        \n",
        "        #os.rename(os.path.join('unsorted',filename), to_copy)\n",
        "        try:\n",
        "            if not os.path.exists(dest):\n",
        "                os.mkdir(dest)\n",
        "            shutil.copy(src, dest)\n",
        "        except:\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}